<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">
<?rfc toc="yes"?>
<?rfc tocompact="yes"?>
<?rfc tocdepth="2"?>
<?rfc tocindent="yes"?>
<?rfc symrefs="yes"?>
<?rfc sortrefs="yes"?>
<?rfc comments="yes"?>
<?rfc inline="yes"?>
<?rfc compact="yes"?>
<?rfc subcompact="no"?>
<rfc category="std" docName="draft-decraeneginsberg-lsr-isis-fast-flooding-00"
     ipr="trust200902">
  <front>
    <title abbrev="IS-IS Fast Flooding">IS-IS Fast Flooding</title>

    <author fullname="Bruno Decraene" initials="B." surname="Decraene">
      <organization>Orange</organization>

      <address>
        <email>bruno.decraene@orange.com</email>
      </address>
    </author>

    <author fullname="Les Ginsberg" initials="L" surname="Ginsberg">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street>821 Alder Drive</street>

          <city>Milpitas</city>

          <code>95035</code>

          <region>CA</region>

          <country>USA</country>
        </postal>

        <email>ginsberg@cisco.com</email>
      </address>
    </author>

    <author fullname="Tony Li" initials="T." surname="Li">
      <organization>Arista Networks</organization>

      <address>
        <postal>
          <street>5453 Great America Parkway</street>

          <city>Santa Clara</city>

          <region>California</region>

          <code>95054</code>

          <country>USA</country>
        </postal>

        <phone/>

        <email>tony.li@tony.li</email>
      </address>
    </author>

    <author fullname="Guillaume Solignac" initials="G." surname="Solignac">
      <address>
        <email>gsoligna@protonmail.com</email>
      </address>
    </author>

    <author fullname="Marek Karasek" initials="M" surname="Karasek">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street>Pujmanove 1753/10a, Prague 4 - Nusle</street>

          <city>Prague</city>

          <region/>

          <code>10 14000</code>

          <country>Czech Republic</country>
        </postal>

        <phone/>

        <facsimile/>

        <email>mkarasek@cisco.com</email>

        <uri/>
      </address>
    </author>

    <author fullname="Chris Bowers" initials="C." surname="Bowers">
      <organization>Juniper Networks, Inc.</organization>

      <address>
        <postal>
          <street>1194 N. Mathilda Avenue</street>

          <city>Sunnyvale</city>

          <region>CA</region>

          <code>94089</code>

          <country>USA</country>
        </postal>

        <email>cbowers@juniper.net</email>
      </address>
    </author>

    <author fullname="Gunter Van de Velde" initials="G."
            surname="Van de Velde">
      <organization>Nokia</organization>

      <address>
        <postal>
          <street>Copernicuslaan 50</street>

          <city>Antwerp</city>

          <code>2018</code>

          <country>Belgium</country>
        </postal>

        <email>gunter.van_de_velde@nokia.com</email>
      </address>
    </author>

    <author fullname="Peter Psenak" initials="P" surname="Psenak">
      <organization>Cisco Systems</organization>

      <address>
        <postal>
          <street>Apollo Business Center Mlynske nivy 43</street>

          <city>Bratislava</city>

          <code>821 09</code>

          <country>Slovakia</country>
        </postal>

        <email>ppsenak@cisco.com</email>
      </address>
    </author>

    <author fullname="Tony Przygienda" initials="T" surname="Przygienda">
      <organization>Juniper</organization>

      <address>
        <postal>
          <street>1137 Innovation Way</street>

          <city>Sunnyvale</city>

          <region>Ca</region>

          <code/>

          <country>USA</country>
        </postal>

        <phone/>

        <facsimile/>

        <email>prz@juniper.net</email>

        <uri/>
      </address>
    </author>

    <date year="2021"/>

    <abstract>
      <t>Current Link State Protocol Data Unit (PDU) flooding rates are much
      slower than what modern networks can support. The use of IS-IS at larger
      scale requires faster flooding rates to achieve desired convergence
      goals. This document discusses the need for faster flooding, the issues
      around faster flooding, and some example approaches to achieve faster
      flooding. It also defines protocol extensions to signal parameters of
      the LSP receiver.</t>
    </abstract>
  </front>

  <middle>
    <section title="Introduction">
      <t>Link state IGPs such as Intermediate-System-to-Intermediate-System
      (IS-IS) depend upon having consistent Link State Databases (LSDB) on all
      Intermediate Systems (ISs) in the network in order to provide correct
      forwarding of data packets. When topology changes occur, new/updated
      Link State PDUs (LSPs) are propagated network-wide. The speed of
      propagation is a key contributor to convergence time.</t>

      <t>Historically, flooding rates have been conservative - on the order of
      10s of LSPs/second. This is the result of guidance in the base
      specification <xref target="ISO10589"/> and early deployments when both
      CPU speeds and interface speeds were much slower and the scale of an
      area was much smaller than they are today.</t>

      <t>As IS-IS is deployed in greater scale both in the number of nodes in
      an area and in the number of neighbors per node, the impact of the
      historic flooding rates becomes more significant. Consider the bringup
      or failure of a node with 1000 neighbors. This will result in a minimum
      of 1000 LSP updates. At typical LSP flooding rates used today (33
      LSPs/second), it would take 30+ seconds simply to send the updated LSPs
      to a given neighbor. Depending on the diameter of the network, achieving
      a consistent LSDB on all nodes in the network could easily take a minute
      or more.</t>

      <t>Increasing the LSP flooding rate therefore becomes an essential
      element of supporting greater network scale.</t>

      <t>Improving the LSP flooding rate is complementary to protocol
      extensions that reduce LSP flooding traffic by reducing the flooding
      topology such as Mesh Groups <xref target="RFC2973"/> or Dynamic
      Flooding <xref target="I-D.ietf-lsr-dynamic-flooding"/> . Reduction of
      the flooding topology does not alter the number of LSPs required to be
      exchanged between two nodes, so increasing the overall flooding speed is
      still beneficial when such extensions are in use. It is also possible
      that the flooding topology can be reduced in ways that prefer the use of
      neighbors that support improved flooding performance.</t>
    </section>

    <section anchor="Language" title="Requirements Language">
      <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
      "SHOULD", "SHOULD NOT", "RECOMMENDED", "NOT RECOMMENDED", "MAY", and
      "OPTIONAL" in this document are to be interpreted as described in BCP 14
      <xref target="RFC2119">RFC 2119</xref> <xref target="RFC8174">RFC
      8174</xref> when, and only when, they appear in all capitals, as shown
      here.</t>
    </section>

    <section anchor="HISTORY" title="Historical Behavior">
      <t>The base specification for IS-IS <xref target="ISO10589"/> was first
      published in 1992 and updated in 2002. The update made no changes in
      regards to suggested timer values. Convergence targets at the time were
      on the order of seconds and the specified timer values reflect that.
      Here are some examples:</t>

      <t><figure>
          <artwork><![CDATA[minimumLSPGenerationInterval - This is the minimum time interval
     between generation of Link State PDUs. A source Intermediate 
     system shall wait at least this long before re-generating one
     of its own Link State PDUs.
				]]></artwork>
        </figure></t>

      <t>The recommended value is 30 seconds.</t>

      <t><figure>
          <artwork><![CDATA[minimumLSPTransmissionInterval - This is the amount of time an 
     Intermediate system shall wait before further propagating 
     another Link State PDU from the same source system. 
				]]></artwork>
        </figure></t>

      <t>The recommended value is 5 seconds.</t>

      <t><figure>
          <artwork><![CDATA[partialSNPInterval - This is the amount of time between periodic 
     action for transmission of Partial Sequence Number PDUs.
     It shall be less than minimumLSPTransmission-Interval.
				]]></artwork>
        </figure></t>

      <t>The recommended value is 2 seconds.</t>

      <t>Most relevant to a discussion of the LSP flooding rate is the
      recommended interval between the transmission of two different LSPs on a
      given interface.</t>

      <t>For broadcast interfaces, <xref target="ISO10589"/> defined:</t>

      <t><figure>
          <artwork><![CDATA[  minimumBroadcastLSPTransmissionInterval - the minimum interval
     between PDU arrivals which can be processed by the slowest 
     Intermediate System on the LAN.
				]]></artwork>
        </figure></t>

      <t>The default value was defined as 33 milliseconds. It is permitted to
      send multiple LSPs "back-to-back" as a burst, but this was limited to 10
      LSPs in a one second period.</t>

      <t>Although this value was specific to LAN interfaces, this has commonly
      been applied by implementations to all interfaces though that was not
      the original intent of the base specification. In fact Section
      12.1.2.4.3 states:</t>

      <t><figure>
          <artwork><![CDATA[  On point-to-point links the peak rate of arrival is limited only 
  by the speed of the data link and the other traffic flowing on 
  that link. 
				]]></artwork>
        </figure></t>

      <t>Although modern implementations have not strictly adhered to the 33
      millisecond interval, it is commonplace for implementations to limit the
      flooding rate to an order of magnitude similar to the 33 ms value.</t>

      <t>In the past 20 years, significant work on achieving faster
      convergence - more specifically sub-second convergence - has resulted in
      implementations modifying a number of the above timers in order to
      support faster signaling of topology changes. For example,
      minimumLSPGenerationInterval has been modified to support millisecond
      intervals, often with a backoff algorithm applied to prevent LSP
      generation storms in the event of a series of rapid oscillations.</t>

      <t>However, the flooding rate has not been fundamentally altered.</t>
    </section>

    <section anchor="FloodingTLV" title="Flooding Parameters TLV">
      <t>This document defines a new Type-Length-Value tuple (TLV) called the
      "Flooding Parameters TLV" that may be included in IS to IS Hellos (IIH)
      or Partial Sequence Number PDUs (PSNPs). It allows IS-IS implementations
      to advertise flooding related parameters and capabilities which may be
      of use to the peer in support of faster flooding.</t>

      <t>Type: TBD1</t>

      <t>Length: variable, the size in octets of the Value field</t>

      <t>Value: One or more sub-TLVs</t>

      <t>Several sub-TLVs are defined in this document. The support of any
      sub-TLV is OPTIONAL.</t>

      <t>For a given IS-IS adjacency, the Flooding Parameters TLV does not
      need to be advertised in each IIH or PSNP. The LSP transmitter uses the
      latest received value for each parameter until a new value is advertised
      by the LSP receiver. However, IIHs and PSNPs are not reliably exchanged,
      and may never be received, so parameters SHOULD be sent even if there is
      no change in value since the last transmission. For a parameter which
      has never been advertised, the LSP transmitter SHOULD use its local
      default value. That value SHOULD be configurable on a per node basis and
      MAY be configurable on a per interface basis.</t>

      <section anchor="LSPReceptionWindow" title="LSP Burst Window sub-TLV">
        <t>The LSP Burst Window sub-TLV advertises the maximum number of LSPs
        that the node can receive with no separation interval between
        LSPs.</t>

        <t>Type: 1</t>

        <t>Length: 4 octets</t>

        <t>Value: number of LSPs that can be sent back to back</t>
      </section>

      <section anchor="InterfaceLSPTransmissionInterval"
               title="LSP Transmission Interval sub-TLV">
        <t>The LSP Transmission Interval sub-TLV advertises the minimum
        interval, in micro-seconds, between LSPs arrivals which can be
        received on this interface, after the maximum number of
        un-acknowledged LSPs has been sent.</t>

        <t>Type: 2</t>

        <t>Length: 4 octets</t>

        <t>Value: minimum interval, in micro-seconds, between two consecutive
        LSPs sent after the burst window has been used</t>

        <t>The LSP Transmission Interval is an advertisement of the receiver's
        steady-state LSP reception rate.</t>
      </section>

      <section anchor="LPP" title="LSPs Per PSNP sub-TLV">
        <t>The sub-TLV LSP Per PSNP (LPP) advertises the number of received
        LSPs that triggers the immediate sending of a PSNP to acknowledge
        them.</t>

        <t>Type: 3</t>

        <t>Length: 2 octets</t>

        <t>Value: number of LSPs acknowledged per PSNP</t>

        <t>A node advertising this sub-TLV with a value LPP MUST send a PSNP
        once LPP LSPs have been received and need to be acknowledged.</t>
      </section>

      <section anchor="Flags" title="Flags sub-TLV">
        <t>The sub-TLV Flags advertises a set of flags. Flags are standardized
        and IANA registered.</t>

        <t>Type: 4</t>

        <t>Length: Indicates the length in octets (1-8) of the Value field.
        The length SHOULD be the minimum required to send all bits that are
        set.</t>

        <t>Value: List of flags.</t>

        <figure>
          <artwork align="left"><![CDATA[
          0 1 2 3 4 5 6 7 ...
         +-+-+-+-+-+-+-+-+...
         |O|              ...
         +-+-+-+-+-+-+-+-+...
				]]></artwork>
        </figure>

        <t>When the O flag is set, the LSP will be acknowledged in the order
        they are received: a PSNP acknowledging N LSPs is acknowledging the N
        oldest LSPs received. The order inside the PSNP is meaningless. If the
        sender keeps track of the order to LSP sent, this indication allows a
        fast detection of loss of LSP. This MUST NOT be used to trigger faster
        retransmission of LSP. This MAY be used to trigger a congestion
        signal.</t>
      </section>

      <section anchor="partialSNPI" title="partialSNPInterval sub-TLV">
        <t>The sub-TLV partialSNPInterval advertises the amount of time in
        milliseconds between periodic action for transmission of Partial
        Sequence Number PDUs. This time will trigger the sending of a PSNP
        even if the number of unacknowledged LSPs received on a given
        interface does not exceed LPP <xref target="LPP"/> .</t>

        <t>Type: 5</t>

        <t>Length: 2 octets</t>

        <t>Value: partialSNPInterval in milliseconds</t>

        <t>A node advertising this sub-TLV SHOULD send a PSNP at least once
        per partialSNPInterval if one or more unacknowledged LSPs have been
        received on a given interface.</t>
      </section>

      <section anchor="TLVoperationLAN" title="Operation on a LAN interface">
        <t>On a LAN interface, all LSPs are link-level multicasts. Each LSP
        sent will be received by all ISs on the LAN and each IS will receive
        LSPs from all transmitters. In this section, we clarify how the
        flooding parameters should be interpreted in the context of a LAN.</t>

        <t>An LSP receiver on a LAN will communicate its desired flooding
        parameters using a single Flooding Parameters TLV, copies of which
        will be received by all transmitters. The flooding parameters sent by
        the LSP receiver MUST be understood as instructions from the receiver
        to each transmitter about the desired maximum transmit characteristics
        of each transmitter. The receiver is aware that there are multiple
        transmitters that can send LSPs to the receiver LAN interface. The
        receiver might want to take that into account by advertising more
        conservative values, e.g. a higher LSP Transmission Interval. When the
        transmitters receive the LSP Transmission Interval value advertised by
        a LSP receiver, the transmitters should rate limit LSPs according to
        the advertised flooding parameters. They should not apply any further
        interpretation to the flooding parameters advertised by the
        receiver.</t>

        <t>A given LSP transmitter will receive multiple flooding parameter
        advertisements from different receivers that may carry different
        flooding parameter values. A given transmitter SHOULD use the most
        convervative value on a per parameter basis. For example, if the
        transmitter receives multiple LSP Burst Window values, it should use
        the smallest value.</t>

        <t>In order for the LSP Burst Window to be a useful parameter, an LSP
        transmitter needs to be able to keep track of the number of
        un-acknowledged LSPs it has sent to a given LSP receiver. On a LAN
        there is no explicit acknowledgment of the receipt of LSPs between a
        given LSP transmitter and a given LSP receiver. However, an LSP
        transmitter on a LAN can infer whether any LSP receiver on the LAN has
        requested retransmission of LSPs from the DIS by monitoring PSNPs
        generated on the LAN. If no PSNPs have been generated on the LAN for a
        suitable period of time, then an LSP transmitter can safely set the
        number of un-acknowledged LSPs to zero. Since this suitable period of
        time is much higher than the fast acknowledgment of LSPs defined in
        <xref target="LSPACKRate"/> , the sustainable transmission rate of
        LSPs will be much slower on a LAN interface than on a point to point
        interface. The LSP Burst Window is still very useful for the first
        burst of LSPs sent, especially in the case of a single node failure
        that requires the flooding of a relatively small number of LSPs.</t>
      </section>
    </section>

    <section anchor="Receiver" title="Performance improvement on the receiver">
      <t>This section defines two behaviors that SHOULD be implemented on the
      receiver.</t>

      <section anchor="LSPACKRate" title="Rate of LSP Acknowledgments">
        <t>On point-to-point networks, PSNP PDUs provide acknowledgments for
        received LSPs. <xref target="ISO10589"/> suggests that some delay be
        used when sending PSNPs. This provides some optimization as multiple
        LSPs can be acknowledged in a single PSNP.</t>

        <t>Faster LSP flooding benefits from a faster feedback loop. This
        requires a reduction in the delay in sending PSNPs.</t>

        <t>The receiver SHOULD reduce its partialSNPInterval. The choice of
        this lower value is a local choice. It may depend on the available
        processing power of the node, the number of adjacencies, and the
        requirement to synchronize the LSDB more quickly. 200 ms seems to be a
        reasonable value.</t>

        <t>In addition to the timer based partialSNPInterval, the receiver
        SHOULD keep track of the number of unacknowledged LSPs per circuit and
        level. When this number exceeds a preset threshold of LSPs Per PSNP
        (LPP), the receiver SHOULD immediately send a PSNP without waiting for
        the PSNP timer to expire. In case of a burst of LSPs, this allows for
        more frequent PSNPs, giving faster feedback to the sender. Outside of
        the burst case, the usual time-based PSNP approach comes into effect.
        If an LSP Burst Window is advertised, LPP SHOULD be lower and the best
        performance is achieved when LPP is an integer fraction of the LSP
        Burst Window. This number SHOULD also be lower or equal to 90 as this
        is the maximum number of LSPs that can be acknowledged in a PSNP,
        hence waiting longer would not reduce the number of PSNPs sent but
        would delay the acknowledgements. Based on experimental evidence, 15
        unacknowledged LSPs is a good value assuming that the LSP Burst Window
        is at least 30.</t>

        <t>By deploying both the time-based and the threshold-based PSNP
        approaches, the receiver can be adaptive to both LSP bursts and
        infrequent LSP updates.</t>

        <t>As PSNPs also consume link bandwidth, packet queue space, and
        protocol processing time on receipt, the increased sending of PSNPs
        should be taken into account when considering the rate at which LSPs
        can be sent on an interface.</t>
      </section>

      <section anchor="PKTPRI" title="Packet Prioritization on Receive">
        <t>There are three classes of PDUs sent by IS-IS:</t>

        <t><list style="symbols">
            <t>Hellos</t>

            <t>LSPs</t>

            <t>Complete Sequence Number PDUs (CSNPs) and PSNPs</t>
          </list>Implementations today may prioritize the reception of Hellos
        over LSPs and SNPs in order to prevent a burst of LSP updates from
        triggering an adjacency timeout which in turn would require additional
        LSPs to be updated.</t>

        <t>CSNPs and PSNPs serve to trigger or acknowledge the transmission of
        specified LSPs. On a point-to-point link, PSNPs acknowledge the
        receipt of one or more LSPs. For this reason, <xref
        target="ISO10589"/> specifies a delay (partialSNPInterval) before
        sending a PSNP so that the number of PSNPs required to be sent is
        reduced. On receipt of a PSNP, the set of LSPs acknowledged by that
        PSNP can be marked so that they do not need to be retransmitted.</t>

        <t>If a PSNP is dropped on reception, the set of LSPs advertised in
        the PSNP cannot be marked as acknowledged and this results in needless
        retransmissions that will further delay transmission of other LSPs
        that have yet to be transmitted. It may also make it more likely that
        a receiver becomes overwhelmed by LSP transmissions.</t>

        <t>It is therefore RECOMMENDED that implementations prioritize the
        receipt of Hellos and then SNPs over LSPs. Implementations MAY also
        prioritize IS-IS packets over other less critical protocols.</t>
      </section>
    </section>

    <section anchor="Control" title="Congestion and Flow Control">
      <section anchor="Overview" title="Overview">
        <t>Ensuring the goodput between two entities is a layer 4
        responsibility as per the OSI model and a typical example is the TCP
        protocol defined in <xref target="RFC0793">RFC 793</xref> and relies
        on the flow control, congestion control, and reliability mechanisms of
        the protocol.</t>

        <t>Flow control creates a control loop between a transmiter and a
        receiver so that the transmitter does not overwhelm the receiver. TCP
        provides a mean for the receiver to govern the amount of data sent by
        the sender through the use of a sliding window.</t>

        <t>Congestion control creates multiple interacting control loops
        between multiple transmitters and multiple receivers to prevent the
        transmitters from overwhelming the overall network. For an IS-IS
        adjacency, the network between two IS-IS neighbors is relatively
        limited in scope and consist of a link that is typically over-sized
        compared to the capability of the IS-IS speakers, but may also
        includes components inside both routers such as a switching fabric,
        line card CPU, and forwarding plane buffers that may experience
        congestion. These resources may be shared across multiple IS-IS
        adjacencies for the system and it is the responsibility of congestion
        control to ensure that these are shared reasonably.</t>

        <t>Reliability provides loss detection and recovery. IS-IS already has
        mechanisms to ensure the reliable transmission of LSPs. This is not
        changed by this document.</t>

        <t>The following two sections provides examples of Flow and/or
        Congestion control algorithms as examples that may be implemented by
        taking advantage of the extensions defined in this document. They are
        non-normative. An implementation may implement any congestion control
        algorithm.</t>
      </section>

      <section anchor="ControlExample1"
               title="Congestion and Flow Control algorithm: Example 1">
        <section anchor="FlowControl" title="Flow control">
          <t>A flow control mechanism creates a control loop between a single
          instance of a transmitter and a single receiver. This example uses a
          mechanism similar to the TCP receive window to allow the receiver to
          govern the amount of data sent by the sender. This receive window
          ('rwin') indicates an allowed number of LSPs that the sender may
          transmit before waiting for an acknowledgment. The size of the
          receive window, in units of LSPs, is initialized with the value
          advertised by the receiver in the LSP Burst Window sub-TLV. If no
          value is advertised, the transmitter should initialize rwin with its
          own local value.</t>

          <t>When the transmitter sends a set of LSPs to the receiver, it
          subtracts the number of LSPs sent from rwin. If the transmitter
          receives a PSNP, then rwin is incremented for each acknowledged LSP.
          The transmitter must ensure that the value of rwin never goes
          negative.</t>

          <section anchor="TLVoperationP2P"
                   title="Operation on a point to point interface">
            <t>By sending the LSP Burst Window sub-TLV, a node advertises to
            its neighbor its ability to receive that many un-acknowledged LSPs
            from the neighbor, with no separation interval. This is akin to a
            receive window or sliding window in flow control. In some
            implementations, this value should reflect the IS-IS socket buffer
            size. Special care must be taken to leave space for CSNP and PSNP
            (SNP) PDUs and IIHs if they share the same input queue. In this
            case, this document suggests advertising an LSP Burst Window
            corresponding to half the size of the IS-IS input queue.</t>

            <t>By advertising an LSP Transmission Interval sub-TLV, a node
            advertises its ability to receive LSPs separated by at least the
            advertised value, outside of LSP bursts.</t>

            <t>The LSP transmitter MUST NOT exceed these parameters. After
            having sent a full burst of un-acknowledged LSPs, it MUST send the
            following LSPs with an LSP Transmission Interval between LSP
            arrivals. For CPU scheduling reasons, this rate may be averaged
            over a small period e.g. 10 to 30ms.</t>

            <t>If either the LSP transmitter or receiver does not adhere to
            these parameters, for example because of transient conditions,
            this causes no fatal condition to the operation of IS-IS. In the
            worst case, an LSP is lost at the receiver and this situation is
            already remedied by mechanisms in <xref target="ISO10589"/> .
            After a few seconds, neighbors will exchange PSNPs (for point to
            point interfaces) or CSNPs (for broadcast interfaces) and recover
            from the lost LSPs. This worst case should be avoided as those
            additional seconds impact convergence time as the LSDB is not
            fully synchronized. Hence it is better to err on the conservative
            side and to under-run the receiver rather than over-run it.</t>
          </section>
        </section>

        <section anchor="CongestionControl" title="Congestion control">
          <t>Whereas flow control prevents the sender from overwhelming the
          receiver, congestion control prevents senders from overwhelming the
          network. For an IS-IS adjacency, the network between two IS-IS
          neighbors is relatively limited in scope and includes a single link
          which is typically over-sized compared to the capability of the
          IS-IS speakers.</t>

          <t>This section describes one congestion control algorithm largely
          inspired by the TCP congestion control algorithm <xref
          target="RFC5681">RFC 5681</xref>. A congestion control algorithm is
          comprised of three elements: a slow start phase, a congestion
          avoidance phase, and a transition between the two.</t>

          <t>The proposed algorithm uses a variable congestion window 'cwin'.
          It plays a role similar to the receive window described before. The
          main difference is that cwin is dynamically changed according to the
          feedback obtained by the PSNPs.</t>

          <section anchor="SlowStart" title="Slow start">
            <t>The goal of the slow start phase is to grow fast and try to
            estimate the effective link capacity.</t>

            <t>The algorithm is circuit scoped. At the beginning of the slow
            start phase, the sender starts with: <list style="symbols">
                <t>a congestion window (cwin) set to one: cwin := 1;</t>

                <t>a number of acked LSPs: acked_lsps := 0;</t>

                <t>a max seen bandwidth: max_bw := 0;</t>

                <t>a current rtt estimate: cur_rtt := NA;</t>

                <t>[a receive window: rwin := ???;</t>

                <t>an estimated bandwidth: bw_est := ???; -- Tony L.]</t>
              </list> <vspace blankLines="0"/></t>

            <t>Upon LSP transmission, a sender records the current time in
            time_sent and acked_lsps in acked_lsps_sent for each LSP.</t>

            <t>Upon receiving a PSNP containing acknowledgements for
            nb_of_lsp_entries LSPs, a sender does the following:</t>

            <figure anchor="slow_start_algorithm">
              <artwork><![CDATA[
cwin := min(cwin + nb_of_lsp_entries, rwin)
acked_lsps += nb_of_lsp_entries
max_diff := 0
max_bw := 0
for every LSP entry:
    time_to_ack := time_now - time_sent
    nb_acked := acked_lsps - acked_lsps_sent
    bw_est := nb_acked/time_to_ack
    max_bw := max(max_bw, bw_est)
    max_diff := max(max_diff, time_to_ack)

if cur_rtt == NA then cur_rtt = max_diff
else cur_rtt := 7/8 * cur_rtt + 1/8 * max_diff
							]]></artwork>
            </figure>

            <t>Starting with the first PSNP, max_bw is checked every cur_rtt.
            Once it has stalled for 3 consecutive times, the congestion
            control algorithm transitions from slow start to congestion
            avoidance. There is bandwidth stalling when the bandwidth has not
            increased by at least 25% compared the last RTT. Note that this is
            similar to Google's BBR <xref
            target="I-D.cardwell-iccrg-bbr-congestion-control"/> slow start
            phase.</t>
          </section>

          <section anchor="CongestionAvoidance" title="Congestion avoidance">
            <t>The goal of the congestion avoidance phase is to try to stay
            close to the effective capacity of the link. For this, the
            algorithm estimates the maximum time taken by the receiver to
            acknowledge a LSP. If an LSP arrives slower than this delay,
            congestion is inferred and cwin is decreased.</t>

            <t>Upon PSNP reception, a sender does the following:</t>

            <figure anchor="congestion_avoidance_algorithm">
              <artwork><![CDATA[
cwin = min(cwin + N/congestion window, rwin)
rtt_est := 0
rtt_var := NA  -- Tony L.
for every LSP entry:
    time_to_ack = time_now - time_sent
    rtt_est = max(rtt_est, time_to_ack)

if rtt_var == NA then rtt_var = rtt_est / 2
else rtt_var = 3/4 * rtt_var + 1/4 * abs(cur_rtt - rtt_est)

cur_rtt = 7/8 * cur_rtt + 1/8 * rtt_est
							]]></artwork>
            </figure>

            <t>Every LSP is checked to be acked within cur_rtt + rtt_var. If
            an LSP arrives late, cwin is divided by two. This behaviour is
            similar to the TCP retransmission timer defined in <xref
            target="RFC6298">RFC 6298</xref>. [What are N and congestion
            window? -- Tony L.]</t>

            <t>There is no need for a timer per LSP. A timer per RTT is
            enough. During an RTT, sent LSPs are recorded in a list list_1.
            Once the RTT is over, list_1 is kept and another list list_2 is
            used to store the next LSPs. LSPs are removed from the lists when
            acked. At the end of the second RTT, every LSP in list_1 should
            have been acked, so list_1 is checked to be empty. List_1 can then
            be reused for the next RTT. [This needs more clarification. --
            Tony L.]</t>

            <t>If there is no transmitted LSP for a fixed period of time, e.g.
            2 seconds, the sender switches back to the slow start phase.</t>
          </section>

          <section anchor="cc_remarks" title="Remarks">
            <t>This algorithm's performance is dependent on the LPP value.
            Indeed, the smaller LPP is, the more information is available for
            the congestion control algorithm to perform well. However, it also
            increases the resources spent on sending PSNPs, so a tradeoff must
            be made. This document recommends to use an LPP of 15 or less.</t>

            <t>Note that this congestion control algorithm benefits from the
            extensions proposed in this document. The advertisement of a
            receive window from the receiver (<xref target="FlowControl"/> )
            avoids the use of an arbitrary maximum value by the sender. The
            faster acknowledgment of LSPs (<xref target="LSPACKRate"/> )
            allows for a faster control loop and hence a faster increase of
            the congestion window in the absence of congestion.</t>
          </section>
        </section>

        <section anchor="sec_determining_values"
                 title="Determining values to be advertised in the Flooding Parameters TLV">
          <t>The values that a receiver advertises do not need to be perfect.
          If the values are too low then the transmitter will not use the full
          bandwidth or available CPU resources. If the values are too high
          then the receiver may drop some LSPs during the first RTT and this
          loss will reduce the usable receive window and the protocol
          mechanisms will allow the adjacency to recover. Flooding several
          orders of magnitude slower than both nodes can achieve will hurt
          performance, as will consistently overloading the receiver.</t>

          <t>The values advertised need not be dynamic as feedback is provided
          by the acknowledgment of LSPs in SNP messages. Acknowledgments
          provide a feedback loop on how fast the LSPs are processed by the
          receiver. They also signal that the LSPs can be removed from receive
          window, explicitly signaling to the sender that more LSPs may be
          sent. By advertising relatively static parameters, we expect to
          produce overall flooding behavior similar to what might be achieved
          by manually configuring per-interface LSP rate limiting on all
          interfaces in the network. The advertised values may be based, for
          example, on an offline tests of the overall LSP processing speed for
          a particular set of hardware and the number of interfaces configured
          for IS-IS. With such a formula, the values advertised in the
          Flooding Parameters TLV would only change when additional IS-IS
          interfaces are configured.</t>

          <t>The values may be updated dynamically, to reflect the relative
          change of load of the receiver, by improving the values when the
          receiver load is getting lower and degrading the values when the
          receiver load is getting higher. For example, if LSPs are regularly
          dropped, or if the queue regularly comes close to being filled, then
          the values may be too high. On the other hand, if the queue is
          barely used (by IS-IS), then values may be too low.</t>

          <t>The values may also be absolute value reflecting relevant average
          hardware resources that are been monitored, typically the amount of
          buffer space used by incoming LSPs. In this case, care must be taken
          when choosing the parameters influencing the values in order to
          avoid undesirable or instable feedback loops. It would be
          undesirable to use a formula that depends, for example, on an active
          measurement of the instantaneous CPU load to modify the values
          advertised in the Flooding Parameters TLV. This could introduce
          feedback into the IGP flooding process that could produce unexpected
          behavior.</t>
        </section>

        <section anchor="OPS_Considerations" title="Operation considerations">
          <t>As discussed in <xref target="TLVoperationLAN"/> , the solution
          is more effective on point to point adjacencies. Hence a broadcast
          interface (e.g. Ethernet) only shared by two IS-IS neighbhors should
          be configured as point to point in order to have a more effective
          flooding.</t>
        </section>
      </section>

      <section anchor="ControlExample2"
               title="Congestion Control algorithm: Example 2">
        <t>This section describes a congestion control algorithm based on
        performance measured by the transmitter without dependance on
        signaling from the receiver.</t>

        <section anchor="Ex2-arch" title="Router Architecture Discussion">
          <t>(The following description is an abstraction - implementation
          details vary.)</t>

          <t>Existing router architectures may utilize multiple input queues.
          On a given line card, IS-IS PDUs from multiple interfaces may be
          placed in a rate limited input queue. This queue may be dedicated to
          IS-IS PDUs or may be shared with other routing related packets.</t>

          <t>The input queue may then pass IS-IS PDUs to a "punt queue" which
          is used to pass PDUs from the data plane to the control plane. The
          punt queue typically also has controls on its size and the rate at
          which packets will be punted.</t>

          <t>An input queue in the control plane may then be used to assemble
          PDUs from multiple linecards, separate the IS-ISs PDU from other
          types of packets, and place the IS-IS PDUs in an input queue
          dedicated to the IS-IS protocol.</t>

          <t>The IS-IS input queue then separates the IS-IS PDUs and directs
          them to an instance specific processing queue. The instance
          specififc processing queue may then further separate the IS-IS PDUs
          by type (IIHs, SNPs, and LSPs) so that separate processing threads
          with varying priorities may be employed to process the incoming
          PDUs.</t>

          <t>In such an architecture, it may be difficult for IS-IS in the
          control plane to accurately track the state of the various input
          queues and determine what value should be advertised as a current
          receive window.</t>

          <t>The following section describes a congestion control algorithm
          based on performance measured by the transmitter without dependance
          on signaling from the receiver.</t>
        </section>

        <section anchor="Ex2-tx" title="Transmitter Based Flow Control">
          <t>The congestion control algorithm described in this section does
          not depend upon direct signaling from the receiver. Instead it
          adapts the tranmsmission rate based on measurement of the actual
          rate of acknowledgments received.</t>

          <t>When flow control is necessary, it can be implemented in a
          straightforward manner based on knowledge of the current flooding
          rate and the current acknowledgement rate. Such an algorithm is a
          local matter and there is no requirement or intent to standardize an
          algorithm. There are a number of aspects which serve as guidelines
          which can be described. </t>

          <t>A maximum target LSP transmission rate (LSPTxMax) SHOULD be
          configurable. This represents the fastest LSP transmission rate
          which will be attempted. This value SHOULD be applicable to all
          interfaces and SHOULD be consistent network wide.</t>

          <t>When the current rate of LSP transmission (LSPTxRate) exceeds the
          capabilities of the receiver, the flow control algorithm needs to
          aggressively reduce the LSPTxRate within a few seconds. Slower
          responsiveness is likely to result in a large number of
          retransmissions which can introduce much larger delays in
          convergence.</t>

          <t>NOTE: Even with modest increases in flooding speed (for example,
          a target LSPTxMax of 300 LSPs/second (10 times the typical rate
          supported today)), a topology change triggering 2100 new LSPs would
          only take 7 seconds to complete.</t>

          <t>Dynamic adjustment of the rate of LSP transmission (LSPTxRate)
          upwards (i.e., faster) SHOULD be done less aggressively and only be
          done when the neighbor has demonstrated its ability to sustain the
          current LSPTxRate.</t>

          <t>The flow control algorithm MUST NOT assume the receive
          capabilities of a neighbor are static, i.e., it MUST handle
          transient conditions which result in a slower or faster receive rate
          on the part of a neighbor.</t>

          <t>The flow control algorithm needs to consider the expected delay
          time in receiving an acknowledgment. It therefore incorporates the
          neighbor partialSNPInterval( <xref target="partialSNPI"/> ) to help
          determine whether acknowlegments are keeping pace with the rate of
          LSPs transmitted. In the absence of an advertisement of
          partialSNPInterval a locally configured value can be used.</t>
        </section>
      </section>
    </section>

    <section anchor="IANA_Consideration" title="IANA Considerations">
      <t>IANA is requested to allocate one TLV from the IS-IS TLV codepoint
      registry.</t>

      <figure anchor="IANA_Registration" title="">
        <preamble/>

        <artwork align="center"><![CDATA[
   Type    Description                    IIH   LSP   SNP   Purge
   ----    ---------------------------    ---   ---   ---   ---
   TBD1    Flooding Parameters TLV         y     n     y     n
			]]></artwork>
      </figure>

      <t>This document creates the following sub-TLV Registry:</t>

      <t>Name: Sub-TLVs for TLV TBD1 (Flooding Parameters TLV).</t>

      <t>Registration Procedure(s): Expert Review</t>

      <t>Expert(s): TBD</t>

      <t>Reference: TBD</t>

      <texttable anchor="table_ex" title="Initial allocations">
        <ttcol align="center">Type</ttcol>

        <ttcol align="left">Description</ttcol>

        <c>0</c>

        <c>Reserved</c>

        <c>1</c>

        <c>LSP Burst Window</c>

        <c>2</c>

        <c>LSP Transmission Interval</c>

        <c>3</c>

        <c>LSPs Per PSNP</c>

        <c>4</c>

        <c>Flags</c>

        <c>5</c>

        <c>partialSNPInterval</c>

        <c>6-255</c>

        <c>Unassigned</c>
      </texttable>

      <t>This document also requests IANA to create a new registry for
      assigning Flag bits advertised in the Flags sub-TLV.</t>

      <t>Name: Flooding Parameters Flags Bits.</t>

      <t>Registration Procedure:</t>

      <t>Expert Review Expert(s): TBD</t>

      <t><figure>
          <artwork><![CDATA[+--------+------------------------+
| Bit #  |  Description           |
+--------|------------------------+
|  0     |  O Flag                |
+--------|------------------------+]]></artwork>
        </figure></t>
    </section>

    <section anchor="Security" title="Security Considerations" toc="default">
      <t>Security concerns for IS-IS are addressed in <xref
      target="ISO10589"/> , <xref target="RFC5304"/> , and <xref
      target="RFC5310"/> . These documents describe mechanisms that provide
      the authentication and integrity of IS-IS PDUs, including SNPs and IIHs.
      These authentication mechanisms are not altered by this document.</t>

      <t>With the cryptographic mechanisms described in <xref
      target="RFC5304"/> and <xref target="RFC5310"/> , an attacker wanting to
      advertise an incorrect Flooding Parameters TLV would have to first
      defeat these mechanisms.</t>

      <t>In the absence of cryptographic authentication, as IS-IS does not run
      over IP but directly over the link layer, it's considered difficult to
      inject false SNP/IHH without having access to the link layer.</t>

      <t>If a false SNP/IIH is sent with a Flooding Parameters TLV set to
      conservative values, the attacker can reduce the flooding speed between
      the two adjacent neighbors which can result in LSDB inconsistencies and
      transient forwarding loops. However, it is not significantly different
      than filtering or altering LSPs which would also be possible with access
      to the link layer. In addition, if the downstream flooding neighbor has
      multiple IGP neighbors, which is typically the case for reliability or
      topological reasons, it would receive LSPs at a regular speed from its
      other neighbors and hence would maintain LSDB consistency.</t>

      <t>If a false SNP/IIH is sent with a Flooding Parameters TLV set to
      aggressive values, the attacker can increase the flooding speed which
      can either overload a node or more likely generate loss of LSPs.
      However, it is not significantly different than sending many LSPs which
      would also be possible with access to the link layer, even with
      cryptographic authentication enabled. In addition, IS-IS has procedures
      to detect the loss of LSPs and recover.</t>

      <t>This TLV advertisement is not flooded across the network but only
      sent between adjacent IS-IS neighbors. This would limit the consequences
      in case of forged messages, and also limits the dissemination of such
      information.</t>
    </section>

    <section anchor="Contributors" title="Contributors">
      <t>The following people gave a substantial contribution to the content
      of this document and should be considered as coauthors:</t>

      <t>Acee Lindem, Cisco Systems, acee@cisco.com</t>

      <t>Jayesh J, Juniper Networks, jayeshj@juniper.net</t>
    </section>

    <section anchor="Acknowledgments" title="Acknowledgments">
      <t>The authors would like to thank Henk Smit, Sarah Chen, Xuesong Geng,
      Pierre Francois and Hannes Gredler for their reviews, comments and
      suggestions.</t>

      <t>The authors would like to thank David Jacquet, Sarah Chen, and
      Qiangzhou Gao for the tests performed on commercial implementations and
      their identification of some limiting factors.</t>
    </section>
  </middle>

  <back>
    <references title="Normative References">
      <?rfc include="reference.RFC.2119"?>

      <?rfc include="reference.RFC.8174"?>

      <?rfc include="reference.RFC.5304"?>

      <?rfc include="reference.RFC.5310"?>

      <?rfc include="reference.RFC.6298"?>

      <reference anchor="ISO10589">
        <front>
          <title>Intermediate system to Intermediate system intra-domain
          routeing information exchange protocol for use in conjunction with
          the protocol for providing the connectionless-mode Network Service
          (ISO 8473)</title>

          <author>
            <organization abbrev="ISO">International Organization for
            Standardization</organization>
          </author>

          <date month="Nov" year="2002"/>
        </front>

        <seriesInfo name="ISO/IEC" value="10589:2002, Second Edition"/>
      </reference>
    </references>

    <references title="Informative References">
      <?rfc include="reference.I-D.ietf-lsr-dynamic-flooding"?>

      <?rfc include="reference.RFC.0793"?>

      <?rfc include="reference.RFC.2973"?>

      <?rfc include="reference.RFC.5681"?>

      <?rfc include="reference.I-D.cardwell-iccrg-bbr-congestion-control"?>
    </references>

    <section anchor="authors-notes" title="Changes / Author Notes">
      <t>[RFC Editor: Please remove this section before publication]</t>

      <t>00: Initial version.</t>
    </section>

    <section anchor="open-issues" title="Issues for Further Discussion">
      <t>[RFC Editor: Please remove this section before publication]</t>

      <t>This section captures issues which the authors either have not yet
      had time to address or on which the authors have not yet reached
      consensus. Future revisions of this document may include new/altered
      text relevant to these issues.</t>

      <t>Issue 1: Placement of the discussion of LPP <xref target="LPP"/>may
      become congestion control algorithm specific.</t>

      <t>Issue 2: Further discussion of the relevance of the router
      architecture to feasibility of different flow/congeston control
      algorithms.</t>

      <t>Issue 3: Discussion of LAN belongs in a separate section - not
      bundled w the new TLV description.</t>
    </section>
  </back>
</rfc>
